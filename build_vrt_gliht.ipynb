{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83aeacd7-237c-492b-a91d-f01c8522087a",
   "metadata": {},
   "source": [
    "# Build a VRT of partially overlapping tifs\n",
    "This builds VRTs of GLiHT data by year and by UTM zone sorted by date (latest dates first)\n",
    "\n",
    "Paul Montesano  \n",
    "Sept 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8707a35-ee78-42da-b45b-5452a54774f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal \n",
    "import glob\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from dateutil.parser import parse\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5303b156-2b49-40bc-8f3f-fbfb6996d049",
   "metadata": {},
   "source": [
    "## Find all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfc08f2f-78cb-4ea4-bb79-3d061ff47a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAINDIR = '/explore/nobackup/people/pmontesa/userfs02/data/gliht/chm'\n",
    "YEAR = 2014\n",
    "TYPE = 'CHM'\n",
    "f_list = glob.glob(f'{MAINDIR}/{YEAR}/*{TYPE}.tif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bc5cf77-b3fe-4778-a360-ec23d2534dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/explore/nobackup/people/pmontesa/userfs02/data/gliht/chm/2014/AK_10Jul2014_l17s40_CHM.tif\n",
      "/explore/nobackup/people/pmontesa/userfs02/data/gliht/chm/2014/AK_20140809_l4s604_CHM.tif\n"
     ]
    }
   ],
   "source": [
    "print(f'{f_list[2]}\\n{f_list[2000]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad04564c-f04c-4929-bb4a-5f322c4c28d7",
   "metadata": {},
   "source": [
    "## Separate files in list according to the UTM zone of their coordinate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44c104d4-19b0-46fe-b04a-8c0ededeea9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 s, sys: 2.55 s, total: 4.9 s\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "list_utm_zones = ['32604','32605','32606','32607']\n",
    "\n",
    "dict_utm_zones = defaultdict(list)\n",
    "\n",
    "# Get lists of files for each UTM zone\n",
    "for f in f_list:\n",
    "    \n",
    "    with rasterio.open(f) as ds:\n",
    "        for zone in list_utm_zones:\n",
    "            if str(ds.crs).split(':')[1] == zone: dict_utm_zones[zone].append(f) \n",
    "\n",
    "dict_utm_zones = dict(dict_utm_zones)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf445df8-8aca-4b9e-9153-2f869db2b44d",
   "metadata": {},
   "source": [
    "## Build a VRT with files of a specific UTM zone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f6b31c-2b45-413a-aec3-5ccc5dd956a9",
   "metadata": {},
   "source": [
    "#### functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74e56235-8497-4758-a37f-8e42590649ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_date(text):\n",
    "    datetimestr = parse(text)\n",
    "    #text = datetime.datetime.strptime(datetimestr, '%Y%m%d')\n",
    "    return datetimestr\n",
    "\n",
    "def filelist_to_date_sorted_df(f_list, date_string_position=1):\n",
    "    \n",
    "    '''\n",
    "    Returns a df sorted by date\n",
    "    This requires:\n",
    "        that the date be at an expected position in the filename \n",
    "    '''\n",
    "    \n",
    "    df = pd.DataFrame(f_list, columns=['path'])\n",
    "    df[\"file\"] = df[\"path\"].apply(lambda x: os.path.basename(x))\n",
    "\n",
    "    # Handle date - this works with multiple\n",
    "    df[\"date\"] = df[\"file\"].str.split('_', expand=True)[date_string_position]\n",
    "    df['date'] = df['date'].apply(clean_date)\n",
    "    df['date'] = pd.to_datetime(df['date']) \n",
    "\n",
    "    # Handle date - this works only with 1 date format\n",
    "    #df[\"date\"] = pd.to_datetime(df[\"path\"].str.split('_', expand=True)[1] , format=\"%d%B%Y\").dt.strftime('%Y%m%d')\n",
    "\n",
    "    df = df.sort_values(by='date', ignore_index=True, ascending=False )\n",
    "    \n",
    "    return df\n",
    "\n",
    "def build_vrt(f_list, out_vrt_fn):\n",
    "    \n",
    "    vrt_options = gdal.BuildVRTOptions(resampleAlg='cubic')\n",
    "    my_vrt = gdal.BuildVRT(out_vrt_fn, f_list, options=vrt_options)\n",
    "    my_vrt = None\n",
    "\n",
    "    print(out_vrt_fn)\n",
    "\n",
    "def dict_gliht_to_vrt(f_list, epsg_utm, date_string_position=1): \n",
    "    \n",
    "    print(epsg_utm)\n",
    "    error_list = []\n",
    "    \n",
    "    try:\n",
    "        # Run function to sort\n",
    "        df = filelist_to_date_sorted_df(f_list, date_string_position=date_string_position)\n",
    "        utm_zone_specific_f_list = df.path.to_list()\n",
    "        \n",
    "        out_vrt_fn = os.path.join(MAINDIR, f'gliht_{TYPE.lower()}_{YEAR}_{epsg_utm}.vrt')\n",
    "        \n",
    "        build_vrt(utm_zone_specific_f_list, out_vrt_fn)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        error_list.append(e)\n",
    "        \n",
    "    return error_list    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b862c8f1-91ac-43e8-9160-07cb51862297",
   "metadata": {},
   "source": [
    "#### Run the gliht to VRT function by UTM zone and collect the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c27f8d-3efd-4cd3-ba31-1441186f3db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32607\n",
      "/explore/nobackup/people/pmontesa/userfs02/data/gliht/chm/gliht_chm_2014_32607.vrt\n",
      "32606\n",
      "Unknown string format: Creek\n",
      "32605\n",
      "/explore/nobackup/people/pmontesa/userfs02/data/gliht/chm/gliht_chm_2014_32605.vrt\n"
     ]
    }
   ],
   "source": [
    "dict_utm_zones_error = defaultdict(list)\n",
    "\n",
    "for epsg_utm, f_list in dict_utm_zones.items():\n",
    "    \n",
    "    error_list = dict_gliht_to_vrt(f_list, epsg_utm, date_string_position=1)\n",
    "    \n",
    "    # Errors get collected here by UTM zone\n",
    "    dict_utm_zones_error[epsg_utm].append(error_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a82ef-6398-45b1-bc12-7e977391e574",
   "metadata": {},
   "source": [
    "#### Handle the UTM zone with a f_list for which an error popped up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c25294-46d4-435c-8c3b-0026e55830f4",
   "metadata": {},
   "source": [
    "##### Bonanza Creek data format is special: no full date string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10645a45-ca48-4703-af45-bc1c1ba31c28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32607\n",
      "32606\n",
      "Creek\n",
      "/explore/nobackup/people/pmontesa/userfs02/data/gliht/chm/gliht_chm_2014_32606.vrt\n",
      "32605\n"
     ]
    }
   ],
   "source": [
    "dict_utm_zones_error = dict(dict_utm_zones_error)\n",
    "\n",
    "for epsg_utm, error_list_list in dict_utm_zones_error.items():\n",
    "    \n",
    "    print(epsg_utm)\n",
    "    \n",
    "    for error_list in error_list_list:\n",
    "        for e in error_list:\n",
    "            \n",
    "            # Get the unexpected string returned from the position of the gliht filename that you thought held the datestring\n",
    "            unexpected_string = e.args[1]\n",
    "            print(unexpected_string)\n",
    "            \n",
    "            # Get the files in this zone's list where the unexpectected string was NOT in (the normally formatted filenames)\n",
    "            gen = filter(lambda x: unexpected_string not in x, dict_utm_zones[epsg_utm]) #Returns a generator\n",
    "            f_list_expected = list(gen)\n",
    "            \n",
    "            gen = filter(lambda x: unexpected_string in x, dict_utm_zones[epsg_utm]) #Returns a generator\n",
    "            f_list_unexpected = list(gen)\n",
    "            \n",
    "            # Get the sorted df from this 'expected' filename list\n",
    "            df_exp = filelist_to_date_sorted_df(f_list_expected, date_string_position=1)\n",
    "            \n",
    "            # Get the sorted df from the 'unexpected' filename list\n",
    "            df_unexp = filelist_to_date_sorted_df(f_list_unexpected, date_string_position=3)\n",
    "            \n",
    "            # Now sort just according to filename\n",
    "            # In this specific case this will sort Bonanza Creek flightlines according to kHz of acquisition (larger first)\n",
    "            df_unexp.sort_values(by='file', ignore_index=True, ascending=False, inplace=True )\n",
    "            \n",
    "            # Combine the 2 dfs\n",
    "            df = pd.concat([df_exp, df_unexp])\n",
    "            \n",
    "            utm_zone_specific_f_list = df.path.to_list()\n",
    "        \n",
    "            out_vrt_fn = os.path.join(MAINDIR, f'gliht_{TYPE.lower()}_{YEAR}_{epsg_utm}.vrt')\n",
    "        \n",
    "            build_vrt(utm_zone_specific_f_list, out_vrt_fn)\n",
    "            \n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ILAB Kernel",
   "language": "python",
   "name": "ilab-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
